// Copyright 2017 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

// Lowering arithmetic
(Add64  x y) -> (ADD  x y)
(AddPtr x y) -> (ADD  x y)
(Add32  x y) -> (ADD x y)
(Add16  x y) -> (ADD x y)
(Add8   x y) -> (ADD x y)
(Add32F x y) -> (FADDS x y)
(Add64F x y) -> (FADDD x y)

(SubPtr x y) -> (SUB x y)
(Sub64 x y) -> (SUB x y)
(Sub32 x y) -> (SUB x y)
(Sub16 x y) -> (SUB x y)
(Sub8 x y) -> (SUB x y)
(Sub32F x y) -> (FSUBS x y)
(Sub64F x y) -> (FSUBD x y)

(Mul64 x y) -> (MULD x y)
(Mul32 x y) -> (MULD x y)
(Mul16 x y) -> (MULD x y)
(Mul8 x y) -> (MULD x y)
(Mul32F x y) -> (FMULS x y)
(Mul64F x y) -> (FMULD x y)

(Div64 x y) -> (SDIVD x y)
(Div32 x y) -> (SDIVD x y)
(Div16 x y) -> (SDIVD x y)
(Div8 x y) -> (SDIVD x y)
(Div64u x y) -> (UDIVD x y)
(Div32u x y) -> (UDIVD x y)
(Div16u x y) -> (UDIVD x y)
(Div8u x y) -> (UDIVD x y)
(Div32F x y) -> (FDIVS x y)
(Div64F x y) -> (FDIVD x y)

(Mod8 x y) -> (Mod64 (SignExt8to64 x) (SignExt8to64 y))
(Mod8u x y) -> (Mod64u (ZeroExt8to64 x) (ZeroExt8to64 y))
(Mod16 x y) -> (Mod64 (SignExt16to64 x) (SignExt16to64 y))
(Mod16u x y) -> (Mod64u (ZeroExt16to64 x) (ZeroExt16to64 y))
(Mod32 x y) -> (Mod64 (SignExt32to64 x) (SignExt32to64 y))
(Mod32u x y) -> (Mod64u (ZeroExt32to64 x) (ZeroExt32to64 y))
(Mod64 x y) -> (SUB x (MULD y (SDIVD x y)))
(Mod64u x y) -> (SUB x (MULD y (UDIVD x y)))

(And64 x y) -> (AND x y)
(And32 x y) -> (AND x y)
(And16 x y) -> (AND x y)
(And8 x y) -> (AND x y)

(Or64 x y) -> (OR x y)
(Or32 x y) -> (OR x y)
(Or16 x y) -> (OR x y)
(Or8 x y) -> (OR x y)

(Xor64 x y) -> (XOR x y)
(Xor32 x y) -> (XOR x y)
(Xor16 x y) -> (XOR x y)
(Xor8 x y) -> (XOR x y)

// unary ops
(Neg64 x) -> (NEG x)
(Neg32 x) -> (NEG x)
(Neg16 x) -> (NEG x)
(Neg8 x) -> (NEG x)
(Neg32F x) -> (FNEGS x)
(Neg64F x) -> (FNEGD x)

(Sqrt x) -> (FSQRTD x)

// Lowering boolean ops
(AndB x y) -> (AND x y)
(OrB x y) -> (OR x y)
(Not x) -> (XORconst [1] x)

// Lowering extension
// Note: we always extend to 64 bits even though some ops don't need that many result bits.
(SignExt8to16  x) -> (MOVBreg x)
(SignExt8to32  x) -> (MOVBreg x)
(SignExt8to64  x) -> (MOVBreg x)
(SignExt16to32 x) -> (MOVHreg x)
(SignExt16to64 x) -> (MOVHreg x)
(SignExt32to64 x) -> (MOVWreg x)

(ZeroExt8to16  x) -> (MOVUBreg x)
(ZeroExt8to32  x) -> (MOVUBreg x)
(ZeroExt8to64  x) -> (MOVUBreg x)
(ZeroExt16to32 x) -> (MOVUHreg x)
(ZeroExt16to64 x) -> (MOVUHreg x)
(ZeroExt32to64 x) -> (MOVUWreg x)

(Trunc16to8  x) -> (MOVBreg x)
(Trunc32to8  x) -> (MOVBreg x)
(Trunc32to16 x) -> (MOVHreg x)
(Trunc64to8  x) -> (MOVBreg x)
(Trunc64to16 x) -> (MOVHreg x)
(Trunc64to32 x) -> (MOVWreg x)

// Lowering constants
(Const8   [val]) -> (MOVWconst [val])
(Const16  [val]) -> (MOVWconst [val])
(Const32  [val]) -> (MOVWconst [val])
(Const64  [val]) -> (MOVDconst [val])
(Const32F [val]) -> (FMOVSconst [val])
(Const64F [val]) -> (FMOVDconst [val])
(ConstNil) -> (MOVDconst [0])
(ConstBool [b]) -> (MOVWconst [b])

(Addr {sym} base) -> (MOVDaddr {sym} base)

(Store [8] ptr val mem) -> (MOVDstore ptr val mem)
